This folder contains scripts for processing the PDB files of the pMHC complexes into featurized graphs, using [deeprank2](https://github.com/DeepRank/deeprank2) package. The majority of .py scripts have a corresponding .sh script that can be submitted to the job scheduler for launching the .py script taking advantage of parallelization and/or multiple processors. Paths specifically refer to our shared cluster on Snellius. Please refer to [deeprank2 documentation](https://deeprank2.readthedocs.io/en/latest/?badge=latest) for in-depth details about the classes/methods used parameters. 

- `1_generate_features.py`: script for processing the PDB files into graphs (and grids) and generating nodes and edges features. The processed data are saved into HDF5 files. All the parameters are set at the beginning of the .py script. 
- `2_feat_pandas_hist.py`: script for reading in the HDF5 files containing graphs (and grids) and putting them into a Pandas Dataframe, which is saved into a FEATHER file. Histograms showing the distributions for all the features are also generated, and are saved into PNG images. 
- `3_explore_feat.py`: script for plotting histograms, means and standard deviation of the features, reading the FEATHER file generated in the above step, and saving the histograms into PNG images. 
- `4_corr_analysis.py`: script for plotting Pearson correlation heatmaps for the processed data (one heatmap for nodes features and one for edge features), reading them from the FEATHER file, and saving the heatmaps into PNG images. 
- `add_targets.py`: script for adding targets into HDF5 files (e.g., clustered peptide/allele value for each data point), reading them in from CSV files.
- `copy_snellius_data_sample.py`: script for copying to the user home folder a subset of PDB files.
- `save_missing_ids.py`: script for saving the IDs of the data points not saved to the HDF5 files, but present in the initial list of PDB models AND in the chosen CSV, so the ones which are missing BUT supposed to be in the HDF5 files. This may be a good start for debugging the data generation process.