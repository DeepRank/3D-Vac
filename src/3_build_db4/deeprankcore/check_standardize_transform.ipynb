{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyulin/anaconda3/envs/deeprank_gpu/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Union\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import cProfile, pstats, io\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "from deeprankcore.dataset import GraphDataset\n",
    "from deeprankcore.domain import nodestorage as Nfeat\n",
    "from deeprankcore.domain import edgestorage as Efeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_day = '230329'\n",
    "run_day_data = '230329'\n",
    "project_folder = '/projects/0/einf2380/'\n",
    "project_folder_sample = '/home/cyulin/snellius_data_sample/'\n",
    "data = 'pMHCI'\n",
    "resolution = 'residue' # either 'residue' or 'atomic'\n",
    "target_dataset = 'binary'\n",
    "features = 'electrostatic'\n",
    "protein_class = 'I'\n",
    "target_data = 'BA'\n",
    "resolution_data = 'residue' # either 'residue' or 'atomic'\n",
    "cluster_dataset = None # 'cl_allele'# None # 'allele_type'\n",
    "cluster_dataset_type = 'string' # None # 'string'\n",
    "# train_clusters = [0, 1, 2, 3, 4, 7, 9]\n",
    "# val_clusters = [5, 8]\n",
    "test_clusters = ['C']\n",
    "\n",
    "# Target/s\n",
    "target_group = 'target_values'\n",
    "target_dataset = 'binary'\n",
    "task = 'classif'\n",
    "\n",
    "folder_data = f'{project_folder}/data/pMHC{protein_class}/features_output_folder/GNN/{resolution_data}/{run_day_data}'\n",
    "input_data_path = glob.glob(os.path.join(folder_data, 'residue-3328373.hdf5'))\n",
    "output_folder =f'{project_folder_sample}/data/pMHC{protein_class}/features_output_folder/GNN/{resolution_data}/{run_day_data}'\n",
    "\n",
    "# Loggers\n",
    "_log = logging.getLogger('')\n",
    "_log.setLevel(logging.INFO)\n",
    "\n",
    "#fh = logging.FileHandler(os.path.join(exp_path, 'training.log'))\n",
    "sh = logging.StreamHandler(sys.stdout)\n",
    "#fh.setLevel(logging.INFO)\n",
    "sh.setLevel(logging.INFO)\n",
    "formatter_fh = logging.Formatter('[%(asctime)s] - %(name)s - %(message)s',\n",
    "                               datefmt='%a, %d %b %Y %H:%M:%S')\n",
    "#fh.setFormatter(formatter_fh)\n",
    "\n",
    "#_log.addHandler(fh)\n",
    "_log.addHandler(sh)\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_arr=['distance']\n",
    "\n",
    "#hdf5_pandas = os.path.join(output_folder, f'{resolution}_pandas.feather')\n",
    "images_path = os.path.join(output_folder, 'images_new')\n",
    "if not os.path.exists(images_path):\n",
    "    os.makedirs(images_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hist( # pylint: disable=too-many-arguments, too-many-branches, useless-suppression\n",
    "        df,\n",
    "        features: Union[str,List[str]],\n",
    "        fname: str = 'features_hist.png',\n",
    "        bins: Union[int,List[float],str] = 10,\n",
    "        figsize: Tuple = (15, 15),\n",
    "        log: bool = False\n",
    "):\n",
    "    \n",
    "    if not isinstance(features, list):\n",
    "        features = [features]\n",
    "\n",
    "    features_df = [col for feat in features for col in df.columns.values.tolist() if feat in col]\n",
    "    \n",
    "    means = [\n",
    "        round(np.concatenate(df[feat].values).mean(), 1) if isinstance(df[feat].values[0], np.ndarray) \\\n",
    "        else round(df[feat].values.mean(), 1) \\\n",
    "        for feat in features_df]\n",
    "    devs = [\n",
    "        round(np.concatenate(df[feat].values).std(), 1) if isinstance(df[feat].values[0], np.ndarray) \\\n",
    "        else round(df[feat].values.std(), 1) \\\n",
    "        for feat in features_df]\n",
    "\n",
    "    if len(features_df) > 1:\n",
    "\n",
    "        fig, axs = plt.subplots(len(features_df), figsize=figsize)\n",
    "\n",
    "        for row, feat in enumerate(features_df):       \n",
    "            if isinstance(df[feat].values[0], np.ndarray):\n",
    "                if(log):\n",
    "                    log_data = np.log(np.concatenate(df[feat].values))\n",
    "                    log_data[log_data == -np.inf] = 0\n",
    "                    axs[row].hist(log_data, bins=bins)\n",
    "                else:\n",
    "                    axs[row].hist(np.concatenate(df[feat].values), bins=bins)\n",
    "            else:\n",
    "                if(log):\n",
    "                    log_data = np.log(df[feat].values)\n",
    "                    log_data[log_data == -np.inf] = 0 \n",
    "                    axs[row].hist(log_data, bins=bins)\n",
    "                else:\n",
    "                    axs[row].hist(df[feat].values, bins=bins)\n",
    "            axs[row].set(xlabel=f'{feat} (mean {means[row]}, std {devs[row]})', ylabel='Count')\n",
    "        fig.tight_layout()\n",
    "\n",
    "    elif len(features_df) == 1:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111)\n",
    "        if isinstance(df[features_df[0]].values[0], np.ndarray):\n",
    "            if(log):\n",
    "                log_data = np.log(np.concatenate(df[features_df[0]].values))\n",
    "                log_data[log_data == -np.inf] = 0\n",
    "                ax.hist(log_data, bins=bins)\n",
    "            else:\n",
    "                ax.hist(np.concatenate(df[features_df[0]].values), bins=bins)\n",
    "        else:\n",
    "            if(log):\n",
    "                log_data = np.log(df[features_df[0]].values)\n",
    "                log_data[log_data == -np.inf] = 0\n",
    "                ax.hist(log_data, bins=bins)\n",
    "            else:\n",
    "                ax.hist(df[features_df[0]].values, bins=bins)\n",
    "        ax.set(xlabel=f'{features_df[0]} (mean {means[0]}, std {devs[0]})', ylabel='Count')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Please provide valid features names. They must be present in the current :class:`DeeprankDataset` children instance.\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fname)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking dataset Integrity...\n",
      "Target classes set up to: [0, 1]\n",
      "   ['/projects/0/einf2380//data/pMHCI/features_output_folder/GNN/residue/230329/residue-3328373.hdf5'] dataset                 : 100%|██████████| 1/1 [00:00<00:00, 332.91it/s, entry_name=residue-3328373.hdf5]\n"
     ]
    }
   ],
   "source": [
    "hdf5_test=\"train.hdf5\"\n",
    "#hdf5_files = glob.glob(os.path.join(output_folder, '*.hdf5'))\n",
    "dataset = GraphDataset(\n",
    "    hdf5_path = input_data_path,\n",
    "    target = target_dataset\n",
    ")\n",
    "df = dataset.hdf5_to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance histogram saved\n"
     ]
    }
   ],
   "source": [
    "for feat in features_arr:\n",
    "    save_hist(df, feat, os.path.join(images_path, f'{feat}_nostandardize.png'), bins=10)\n",
    "    _log.info('%s histogram saved',feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_notrans_dict={'bsa':{'Transformation':None,'Standardization':True},\n",
    "               'res_depth':{'Transformation':None,'Standardization':True},\n",
    "               'info_content':{'Transformation':None,'Standardization':True},\n",
    "               'sasa':{'Transformation':None,'Standardization':True},\n",
    "               'electrostatic':{'Transformation':None,'Standardization':True},\n",
    "               'vanderwaals':{'Transformation':None,'Standardization':True},\n",
    "               'res_size':{'Transformation':None,'Standardization':True},\n",
    "               'res_charge':{'Transformation':None,'Standardization':True},\n",
    "               'hb_donors':{'Transformation':None,'Standardization':True},\n",
    "               'hb_acceptors':{'Transformation':None,'Standardization':True},\n",
    "               'hse':{'Transformation':None,'Standardization':True},\n",
    "               'irc_nonpolar_negative':{'Transformation':None,'Standardization':True},\n",
    "               'irc_nonpolar_nonpolar':{'Transformation':None,'Standardization':True},\n",
    "               'irc_nonpolar_polar':{'Transformation':None,'Standardization':True},\n",
    "               'irc_nonpolar_positive':{'Transformation':None,'Standardization':True},\n",
    "               'irc_polar_polar':{'Transformation':None,'Standardization':True},\n",
    "               'irc_polar_positive':{'Transformation':None,'Standardization':True},\n",
    "               'irc_total':{'Transformation':None,'Standardization':True},\n",
    "               'irc_negative_positive':{'Transformation':None,'Standardization':True},\n",
    "               'irc_positive_positive':{'Transformation':None,'Standardization':True},\n",
    "               'irc_polar_negative':{'Transformation':None,'Standardization':True},\n",
    "               'irc_negative_negative':{'Transformation':None,'Standardization':True},\n",
    "               'res_mass':{'Transformation':None,'Standardization':True},\n",
    "               'res_pI':{'Transformation':None,'Standardization':True},\n",
    "               'distance':{'Transformation':None,'Standardization':True},\n",
    "               'pssm':{'Transformation':None,'Standardization':True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking dataset Integrity...\n",
      "Target classes set up to: [0, 1]\n",
      "   ['/projects/0/einf2380//data/pMHCI/features_output_folder/GNN/residue/230329/residue-3328373.hdf5'] dataset                 : 100%|██████████| 1/1 [00:00<00:00, 373.42it/s, entry_name=residue-3328373.hdf5]\n"
     ]
    }
   ],
   "source": [
    "#hdf5_files = glob.glob(os.path.join(output_folder, '*.hdf5'))\n",
    "dataset_standardize = GraphDataset(\n",
    "    hdf5_path = input_data_path,\n",
    "    target = target_dataset,\n",
    "    feat_trans_dict=feat_notrans_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bsa = []\n",
    "#for idx in range(len(dataset)):\n",
    "    #x = dataset_standardize.get(idx,feat_notrans_dict)\n",
    "    #bsa.append(x.x[:,0])\n",
    "#df_standardize = dataset_standardize.hdf5_to_pandas()\n",
    "#bsa = np.concatenate(bsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(hdf5_test, 'r') as f5:\n",
    "            grp = f5[list(f5.keys())[0]]\n",
    "            # test_node_features=['bsa','hse'] #test node features\n",
    "            # # getting all node features values\n",
    "            # tensor_idx = 0\n",
    "            # features_dict = {}\n",
    "            # for feat in test_node_features:\n",
    "            #     vals = grp[f\"{Nfeat.NODE}/{feat}\"][()]\n",
    "            #     if vals.ndim == 1: # features with only one channel\n",
    "            #         arr = []\n",
    "            #         for entry_idx in range(len(dataset_standardize)):\n",
    "            #             arr.append(dataset_standardize.get(entry_idx,feat_notrans_dict).x[:, tensor_idx])\n",
    "            #         arr = np.concatenate(arr)\n",
    "            #         features_dict[feat] = arr\n",
    "            #         tensor_idx += 1\n",
    "                    \n",
    "            #         #plot histogram\n",
    "            #         fig = plt.figure(figsize=(15, 15))\n",
    "            #         ax = fig.add_subplot(111)\n",
    "            #         ax.hist(features_dict[feat], bins=10)\n",
    "            #         for key, values in features_dict.items():\n",
    "            #             if(key == 'bsa'):\n",
    "            #                 mean = values.mean()\n",
    "            #                 dev = values.std()\n",
    "            #         ax.set(xlabel=f'{test_node_features[0]} (mean {mean}, std {dev})', ylabel='Count')\n",
    "            #         fig.tight_layout()\n",
    "            #         fig.savefig(os.path.join(images_path, f'{feat}_standardize.png'))\n",
    "            #         plt.close(fig)\n",
    "            #     else: #features with multiple channels\n",
    "            #         for ch in range(vals.shape[1]):\n",
    "            #             arr = []\n",
    "            #             for entry_idx in range(len(dataset_standardize)):\n",
    "            #                 arr.append(dataset_standardize.get(entry_idx,feat_notrans_dict).x[:, tensor_idx])\n",
    "            #             tensor_idx += 1\n",
    "            #             arr = np.concatenate(arr)\n",
    "            #             features_dict[feat + f'_{ch}'] = arr\n",
    "                        \n",
    "            #         #plot histogram\n",
    "            #         fig, axs = plt.subplots(3, figsize=(15,15))\n",
    "            #         for ch in range(vals.shape[1]):\n",
    "            #             axs[ch].hist(features_dict[feat + f'_{ch}'], bins=10)\n",
    "            #             mean=features_dict[feat + f'_{ch}'].mean()\n",
    "            #             dev=features_dict[feat + f'_{ch}'].std()\n",
    "            #             axs[ch].set(xlabel=f'{feat}_{ch} (mean {mean}, std {dev})', ylabel='Count')\n",
    "            #         fig.tight_layout()\n",
    "            #         fig.savefig(os.path.join(images_path, f'{feat}_standardize.png'))\n",
    "            #         plt.close(fig)\n",
    "            \n",
    "            # getting all edge features values\n",
    "            tensor_idx = 0\n",
    "            features_dict = {}\n",
    "            test_edge_features=['distance'] #test node features\n",
    "            for feat in test_edge_features:\n",
    "                vals = grp[f\"{Efeat.EDGE}/{feat}\"][()]\n",
    "                if vals.ndim == 1: # features with only one channel\n",
    "                    arr = []\n",
    "                    for entry_idx in range(len(dataset_standardize)):\n",
    "                        arr.append(dataset_standardize.get(entry_idx,feat_notrans_dict).edge_attr[:, tensor_idx])\n",
    "                    arr = np.concatenate(arr)\n",
    "                    features_dict[feat] = arr\n",
    "                    tensor_idx += 1\n",
    "                    \n",
    "                    #plot histogram\n",
    "                    fig = plt.figure(figsize=(15, 15))\n",
    "                    ax = fig.add_subplot(111)\n",
    "                    ax.hist(features_dict[feat], bins=10)\n",
    "                    for key, values in features_dict.items():\n",
    "                        if(key == 'distance'):\n",
    "                            mean = values.mean()\n",
    "                            dev = values.std()\n",
    "                    ax.set(xlabel=f'{test_edge_features[0]} (mean {mean}, std {dev})', ylabel='Count')\n",
    "                    fig.tight_layout()\n",
    "                    fig.savefig(os.path.join(images_path, f'{feat}_standardize.png'))\n",
    "                    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprank_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
