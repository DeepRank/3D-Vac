import subprocess
import re
import argparse

arg_parser = argparse.ArgumentParser(
    description = "Script to dispatch parallelized job on the snellius cluster modelling pMHC complexes from \
    data/externa/processed/to_model.csv (generated by `get_unmodelled_cases.py`). \
    This script first calls `unmodelled_cases.py` to generate the `data/external/processed/to_model.csv` file \
    containing unmodelled cases present in the --input-csv. Then, `allocate_nodes.py` is called to calculate the \
    necessary number of nodes (runned in parallel) based on the running time. \
    The `modelling_job.py` runs for a defined period of time on an allocated number of clusters. \
    At the end of the modelling job, `clean_outputs.py` is called to clean the models from unecessary files.\
    When choosing the running time, it should be known that each core on each node can \
    model around 1280 cases per hour. The number of nodes to allocate for this job is calculated by allocate_nodes.py \
    w.r.t the number of cases per hour per core. Because the anchors are predicted using NetMHCPpan4.1 tool, it should \
    be known that around 1h is necessary to predict anchors for 1280 cases (the additional time is taken care of by \
    the allocate_nodes.py script). This means that if you provided a --running-time of 2 hours, the job will run for 4 hours \
    to be sure that every anchors are predicted.")
arg_parser.add_argument("--running-time", "-t",
    help = "Number of hours allocated for the job to run. Should be in format 00. Default 01.",
    default = "01",
)
arg_parser.add_argument("--input-csv", "-i",
    help = "db1 file path. No default value. Required.",
    required = True,
)
arg_parser.add_argument("--skip-check", "-s",
    help = "Skip the verification of unmodelled cases. By default, if this argument is not provided, models \
    are checked.",
    default = False,
    action = "store_true"
)
arg_parser.add_argument("--models-dir", "-m",
    help="Path to the BA or EL folder where the models are generated",
    default="/projects/0/einf2380/data/pMHCI/models/BA",
)
arg_parser.add_argument("--mhc-class", "-c",
    help="MHC class of the cases",
    choices=['I','II'],
    required=True,
)
a = arg_parser.parse_args();


running_time = a.running_time; #in hour
to_model = ('/').join(a.input_csv.split('/')[:-1]) + "/to_model.csv"

# generate the to_model.csv containing all unmodelled cases from the input csv.  

if a.skip_check == False:
    command_output = subprocess.check_output(
        [
            "sbatch", 
            "get_unmodelled_cases.sh",
            "-f", a.input_csv,
            "-u", # this argument is mandatory to overwrite `to_model.csv`
            "-m", a.models_dir,
            "-t", to_model,
        ]
    ).decode("ASCII");

    jid = int(re.search(r"\d+", command_output).group())

    # run the parallel modeling on n nodes
    subprocess.run(
        [
            "sbatch",
            f"--dependency=afterany:{jid}",
            "allocate_nodes.sh",
            "-t", running_time,
            "-m", a.mhc_class,
            "-i", to_model,
        ]
    )
else: 
    subprocess.run(
        [
            "sbatch",
            "allocate_nodes.sh",
            "-t", running_time,
            "-m", a.mhc_class,
            "-i", to_model,
            "-p", a.models_dir,
        ]
    )