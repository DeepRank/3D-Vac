{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Generates PSFM for alignment cores from each cluster set files provided in the `paths`. Calculate then the KL divergence between each possible combination of cluster vs cluster (one to one and one to many) divergence and plots.\n",
    "For each cluster set, the distribution of KLD values can be visualized and compared between different clustering paramaters. To plot several kld distribution and compare them, a pickle file should be created beforehand storing each KLD sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables for the experiment:\n",
    "path_to_gibbs_cluster_output = \"/home/daqop/mountpoint_snellius/softwares/gibbscluster-2.0/run/all_hla_peptides_clusters_1_15_with_trash_j_4_3290162/cores/gibbs.*of*.core\"\n",
    "experiment_title = \"l_012_j_4\"\n",
    "test_filename = \"all_kld_tests_lambda_j.pkl\" # file where all sets of KLDs values are saved to be plotted together\n",
    "exp = \"one2many\" #one2many or one2one\n",
    "title_for_plot = \"test\" # title of the plot for the saved file pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob(path_to_gibbs_cluster_output)\n",
    "alphabet = list(\"ARNDCQEGHILKMFPSTWYV\") # universe of possible AA\n",
    "pseudocount = 10 # to prevent 0 in the matrice\n",
    "p_matrices = [] # PSFM matrices are stacked here\n",
    "p_matrice_names = [] # IDs for each PSFM\n",
    "for path in paths:\n",
    "    core_f = open(path, \"r\")\n",
    "    f_name = path.split(\"/\")[-1].replace(\".core\", \"\")\n",
    "    # using regexp extract the cluster set and cluster name from the filename\n",
    "    cluster = int(re.search(\"(?<=gibbs.)[0-9]*\", f_name).group()) \n",
    "    cluster_set = int(re.search(\"(?<=of)[0-9]*\", f_name).group())\n",
    "    p_matrice_names.append({\n",
    "        \"cluster\": cluster,\n",
    "        \"cluster_set\": cluster_set\n",
    "    })\n",
    "    peptides = [] # 9-mer cores of the alignment file\n",
    "    for l in core_f:\n",
    "        peptides.append(list(l.replace(\"\\n\",\"\")))\n",
    "    peptides = np.array(peptides)\n",
    "    psfm_matrice_for_one_cluster = np.stack([\n",
    "        (np.count_nonzero(peptides == alphabet[i], axis=0)+pseudocount) / (peptides.shape[0]+pseudocount*len(alphabet)) \n",
    "        for i in range(len(alphabet))\n",
    "    ])\n",
    "    p_matrices.append(psfm_matrice_for_one_cluster)\n",
    "p_matrices = np.stack(p_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate one-to-one\n",
    "all_klds = [] # all KL divergences for each cluster vs cluster comparison\n",
    "all_kld_indices = [] # ID of each KLD value\n",
    "for i in range(1,16):\n",
    "    for j in range(1, i+1):\n",
    "        # Calculates the divergence between the matrice of cluster p and compare to matrice of cluster q.\n",
    "        # For n the number of cluster in each cluster set, the number of KLD values is n^2\n",
    "        p_matrice = [p_matrices[p_matrice_names.index(name)] for name in p_matrice_names if name[\"cluster\"] == j and name[\"cluster_set\"] == i][0]\n",
    "        for k in range(1, i+1):\n",
    "            q_matrice = [p_matrices[p_matrice_names.index(name)] for name in p_matrice_names if name[\"cluster_set\"] == i and name[\"cluster\"] == k][0]\n",
    "            kld_pq = np.sum(p_matrice*np.log(p_matrice/q_matrice), axis=0)\n",
    "            all_kld_indices.append(\n",
    "                [j,k,i] # p,q and cluster_set define each KLD value\n",
    "            )\n",
    "            all_klds.append(kld_pq)\n",
    "all_klds = np.stack(all_klds)\n",
    "all_kld_indices = np.array(all_kld_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster_set  cluster  mean_kld_for_cluster  cluster_max_distance\n",
      "0              1        1              0.000000              0.000000\n",
      "2              2        2              0.208114              0.208114\n",
      "3              3        1              0.289625              0.289625\n",
      "7              4        2              0.347674              0.347674\n",
      "11             5        2              0.365734              0.365734\n",
      "19             6        5              0.404494              0.404494\n",
      "24             7        4              0.439988              0.439988\n",
      "31             8        4              0.440759              0.440759\n",
      "40             9        5              0.458814              0.458814\n",
      "48            10        4              0.479002              0.479002\n",
      "57            11        3              0.468442              0.468442\n",
      "73            12        8              0.477518              0.477518\n",
      "88            13       11              0.487473              0.487473\n",
      "104           14       14              0.493757              0.493757\n",
      "113           15        9              0.511480              0.511480\n"
     ]
    }
   ],
   "source": [
    "# now that we have every KLD values for each cluster vs cluster combination in each cluster set, each\n",
    "# values are saved in a pickle file to be ploted later with different sets of KLDs\n",
    "all_klds_condition = {\n",
    "    \"title\": experiment_title, # this title will be used as legend in the plot\n",
    "    \"klds\": [] # KLD values go in here\n",
    "}\n",
    "\n",
    "one2many_mean_klds = []\n",
    "for i in range(1,16):\n",
    "    if exp == \"one2one\":\n",
    "        cluster_set_indices = [ind for ind in range(len(all_kld_indices)) if all_kld_indices[ind][2] == i]\n",
    "        # actually the KLD distance is calculated for each position in the PSFM. Thus, the KLD of one cluster\n",
    "        # to the other is defined by a vector of length 9. Each cluster-to-cluster divergence is defined by\n",
    "        # the mean value over the vector:\n",
    "        klds = all_klds[cluster_set_indices].mean(axis=1, dtype=np.float64)\n",
    "\n",
    "        # # if i == 10: # this line is used to explore a specific cluster set with sorted distances\n",
    "        # #     sorted_indices = np.argsort(klds)+j\n",
    "        # #     indices = all_kld_indices[sorted_indices]\n",
    "        # #     print(indices[-10:]) # get the 10 most distance combination of cluster vs cluster.\n",
    "        all_klds_condition[\"klds\"].append(klds)\n",
    "    if exp == \"one2many\":\n",
    "        for j in range(1, i+1):\n",
    "            cluster_set_indices = [ind for ind in range(len(all_kld_indices))\n",
    "                if all_kld_indices[ind][2] == i and all_kld_indices[ind][0] == j\n",
    "            ]\n",
    "            klds = all_klds[cluster_set_indices].mean(axis=1, dtype=np.float64)\n",
    "            one2many_mean_klds.append({\n",
    "                \"cluster_set\": i,\n",
    "                \"cluster\": j,\n",
    "                \"mean_kld_for_cluster\": klds.mean()\n",
    "            })\n",
    "if exp == \"one2many\":\n",
    "    kld_df = pd.DataFrame(one2many_mean_klds)\n",
    "    # kld_group = kld_df.groupby([\"cluster_set\"])[\"klds\"]\n",
    "    kld_df['cluster_max_distance'] = kld_df.groupby(['cluster_set'])['mean_kld_for_cluster'].transform(max)\n",
    "    print(kld_df.loc[kld_df[\"cluster_max_distance\"] == kld_df[\"mean_kld_for_cluster\"]])\n",
    "\n",
    "# all_kld_tests_arr = pickle.load(open(test_filename, \"rb\"))\n",
    "# all_kld_tests_arr.append(all_klds_condition)\n",
    "# pickle.dump(all_kld_tests_arr, open(test_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot KLDs from a pkl file\n",
    "fig = go.Figure()\n",
    "all_kld_tests = pickle.load(open(\"all_kld_tests_lambda_j.pkl\", \"rb\"))\n",
    "x = []\n",
    "for i in range(len(all_kld_tests)):\n",
    "    for j in range(1,16):\n",
    "        x.extend([j]*(j*j))\n",
    "for i in range(len(all_kld_tests)):\n",
    "    klds = []\n",
    "    cond = all_kld_tests[i]\n",
    "    for k in cond[\"klds\"]:\n",
    "        klds.extend(k.tolist())\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            x = x,\n",
    "            y = klds,\n",
    "            name = cond[\"title\"]\n",
    "        )\n",
    "    )\n",
    "fig.update_layout(\n",
    "    title=\"The distribution of KL divergence values between clusters for each cluster set\",\n",
    "    xaxis_title=\"Cluster set\",\n",
    "    yaxis_title=\"Cluster-cluster divergence in one cluster set\",\n",
    "    boxmode=\"group\",\n",
    "    autosize=False,\n",
    "    width = 1600,\n",
    "    height = 800\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image(f\"../../reports/figures/gibbs_clusters/{title_for_plot}.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0f11ea36265c7a09575b72ab023a91955654eee7154dd519d25c1189c46f9fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
