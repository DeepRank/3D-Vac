from matplotlib import pyplot as plt
import torch.nn.functional as F
import torch.nn as nn
import torch
import h5py
import os
import argparse
import numpy as np

arg_parser = argparse.ArgumentParser(
    description = ""
)
arg_parser.add_argument("--metricsfile", "-f",
    help="path of HDF5 file containing metrics per epoch generated by deeprank.learn.NeuralNet",
    type=str,
    required=True
)
arg_parser.add_argument("--overwrite-plots", "-o",
    help="overwrite plots in output folder if already present",
    action='store_true',
    default= False,
)

def check_path_exists(pathname):
    if os.path.exists(pathname):
        return True
    
def export_losses(losses_dict, n_epochs, outdir, best_model=False, show=False, overwrite=False):
    """Plot the losses vs the epoch.
    
    Args:
        figname (str): name of the file where to export the figure
    """
    
    color_plot = ['red', 'blue', 'green']
    labels = ['train', 'valid', 'test']
    
    # if best_model:
    #     best_model = ((np.where(np.array(losses_dict['valid']) == self.min_error['valid'])[0][-1] \
    #                     +1)*self.frac_measure)-1
    
    fig, ax = plt.subplots()
    for ik, name in enumerate(losses_dict):
        # if name == 'test' or name == 'train':
        #     x = np.linspace(1, n_epochs, len(losses_dict[name]))
        # else:
        #     x = np.linspace(1, n_epochs, len(losses_dict[name]))
        if name == 'train':
            x = np.linspace(1, n_epochs, len(losses_dict[name]))
        else:
            x = np.linspace(0, n_epochs, len(losses_dict[name]))
            
        plt.plot(   x,
                    np.array(losses_dict[name]),
                    c = color_plot[ik],
                    label = labels[ik])
        plt.scatter(   x,
                    np.array(losses_dict[name]),
                    c = color_plot[ik],
                    s=8, marker='D',
                    label='_nolegend_')

    if best_model:
        plt.axvline(x = best_model+1, #adjustment due to epoch -001 
                    color = 'orchid', 
                    ls='--', 
                    label = 'best model')
        
    legend = ax.legend(loc='upper right')
    
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Losses')
    ax.set_xticks(np.arange(0, len(x)+1, 1))
    
    if show:
        plt.show()
        # outdir= '/home/severin/teststuff/deeprank_plot'
        figname = os.path.join(outdir, 'losses.png')
        if not check_path_exists(figname) or overwrite:
            print(f'writing losses plot to {figname}')
            plt.savefig(figname, dpi=300)
        elif check_path_exists(figname):
            print(f'path {figname} exists, give --overwrite as argument if file needs to be overwritten')
        
    plt.close()
    
def export_metrics(metricname:str, classmetrics:dict, exec_epochs:int, outdir:str=None, 
                   best_model=False, show=False, overwrite=False):
    """seperate plot for each metric (e.g accuracy/auc) over the epochs
    
    Args:
        metricname (str): name of the metric to obtain from classmetrics dict and to plot
        exec_epochs (int): number of executed epochs (may have been corrected for early stopping)
    """
    
    # if best_model:
    #     best_model = ((np.where(np.array(f_metrics['losses/valid'][:]) == self.min_error['valid'])[0][-1]+1)\
    #     *1)-1        
    
    color_plot = ['red', 'blue', 'green']
    labels = ['train', 'valid', 'test']
    
    data = classmetrics[metricname]
    fig, ax = plt.subplots()
    for ik, name in enumerate(data):
        
        if name == 'train':
            x = np.linspace(1, exec_epochs, len(data[name]))
        else:
            x = np.linspace(0, exec_epochs, len(data[name]))
        plt.plot(x, np.array(data[name]), c=color_plot[ik], label=labels[ik])
        
    if best_model:
        plt.axvline(x = best_model+1, #adjustment due to epoch -001 
                    color = 'orchid', 
                    ls='--', 
                    label = 'best model')
    
    legend = ax.legend(loc='upper left')
    ax.set_xlabel('Epoch')
    ax.set_ylabel(metricname.upper())
    ax.set_xticks(np.arange(0, len(x)+1, 1))
    
    if show:
        print(f'\n --> {metricname.upper()} Plot')
        plt.show()
    
        # outdir= '/home/severin/teststuff/deeprank_plot'
        figname = os.path.join(outdir, metricname + '.png')
        if not check_path_exists(figname) or overwrite:
            print(f'writing metrics ({m}) plot to {figname}')
            plt.savefig(figname, dpi=300)
        elif check_path_exists(figname):
            print(f'path {figname} exists, give --overwrite as argument if file needs to be overwritten')
        
    plt.close()
    if best_model:
        return np.array(data[name])[best_model]
    
    
    
def get_losses_per_epoch(f_metrics, f_metrics_keys):
    criterion = nn.CrossEntropyLoss(weight = None, reduction='mean')
    losses_dict = {'train': [], 'valid': [], 'test': []}
    for epoch in f_metrics_keys:
        for subset in f_metrics[epoch]:
            outputs = np.array(f_metrics[f'{epoch}/{subset}/outputs'])
            targets = np.array(f_metrics[f'{epoch}/{subset}/targets'])
            
            loss = criterion(torch.Tensor(outputs), torch.Tensor(targets).long())
            
            if subset == 'test':
                losses_dict['test'].append(loss)
            elif subset == 'valid':
                losses_dict['valid'].append(loss)
            else:
                losses_dict['train'].append(loss)
    return losses_dict

def get_metrics_per_epoch(f_metrics, f_metrics_keys, metrics):
    metrics_dir = {}
    for m in metrics:
        metrics_dir[m] = {'train': [], 'valid': [], 'test': []}
        
    for i, epoch in enumerate(f_metrics_keys):
        if i == 0:
            for m in metrics:
                try:
                    metrics_dir[m]['valid'].append(f_metrics[f'{epoch}/valid/{m}'][()])
                    metrics_dir[m]['test'].append(f_metrics[f'{epoch}/test/{m}'][()])
                except KeyError:
                    f_metrics.close()
                    raise Exception(f'exception at line 159 caused by m {m} and epoch {epoch}')
            
        else:
            for m in metrics:
                metrics_dir[m]['train'].append(f_metrics[f'{epoch}/train/{m}'][()])
                metrics_dir[m]['valid'].append(f_metrics[f'{epoch}/valid/{m}'][()])
                metrics_dir[m]['test'].append(f_metrics[f'{epoch}/test/{m}'][()])
    return metrics_dir

if __name__ == "__main__":
    
    metrics = ['acc', 'auc', 'f1', 'mcc', 'tnr', 'tpr']
    
    args = arg_parser.parse_args()
    
    overwrite = args.overwrite_plots
    
    training_path = os.path.dirname(args.metricsfile)
    
    f_metrics = h5py.File(args.metricsfile, 'r')
    
    if list(f_metrics.keys())[-1] == 'losses':
        f_metrics_keys = list(f_metrics.keys())[:-1]
    else:
        f_metrics_keys = list(f_metrics.keys())
        
    metrics_dict = get_metrics_per_epoch(f_metrics, f_metrics_keys, metrics)
    losses_dict = get_losses_per_epoch(f_metrics, f_metrics_keys)
    
    f_metrics.close()
    
    export_losses(losses_dict, len(f_metrics_keys), training_path)
    
    best_model = (np.where(np.array(
        f_metrics['losses/valid'][:]) == min(f_metrics['losses/valid'][:]))[0][-1])
    
    for m in metrics:
        export_metrics(m, metrics_dict, len(f_metrics_keys), training_path, best_model=best_model)
