{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    average_precision_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_fullname</th>\n",
       "      <th>exp_path</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>input_data_path</th>\n",
       "      <th>protein_class</th>\n",
       "      <th>target_data</th>\n",
       "      <th>resolution</th>\n",
       "      <th>task</th>\n",
       "      <th>node_features</th>\n",
       "      <th>...</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>testing_accuracy</th>\n",
       "      <th>training_precision</th>\n",
       "      <th>validation_precision</th>\n",
       "      <th>testing_precision</th>\n",
       "      <th>training_recall</th>\n",
       "      <th>validation_recall</th>\n",
       "      <th>testing_recall</th>\n",
       "      <th>test_clusters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>exp_100k_final_feat_trans_seed11_rmpssm_0</th>\n",
       "      <td>exp_100k_final_feat_trans_seed11_rmpssm_0_230530</td>\n",
       "      <td>./experiments/exp_100k_final_feat_trans_seed11...</td>\n",
       "      <td>30/May/2023_02:50:52</td>\n",
       "      <td>30/May/2023_05:29:15</td>\n",
       "      <td>['/projects/0/einf2380/data/pMHCI/features_out...</td>\n",
       "      <td>I</td>\n",
       "      <td>BA</td>\n",
       "      <td>residue</td>\n",
       "      <td>classif</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.806</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_100k_final_nostd_seed44_rmpssm_0</th>\n",
       "      <td>exp_100k_final_nostd_seed44_rmpssm_0_230529</td>\n",
       "      <td>./experiments/exp_100k_final_nostd_seed44_rmps...</td>\n",
       "      <td>29/May/2023_22:49:24</td>\n",
       "      <td>30/May/2023_03:26:25</td>\n",
       "      <td>['/projects/0/einf2380/data/pMHCI/features_out...</td>\n",
       "      <td>I</td>\n",
       "      <td>BA</td>\n",
       "      <td>residue</td>\n",
       "      <td>classif</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.739</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_100k_final_nostd_seed55_rmpssm_0</th>\n",
       "      <td>exp_100k_final_nostd_seed55_rmpssm_0_230529</td>\n",
       "      <td>./experiments/exp_100k_final_nostd_seed55_rmps...</td>\n",
       "      <td>29/May/2023_22:49:43</td>\n",
       "      <td>30/May/2023_03:26:09</td>\n",
       "      <td>['/projects/0/einf2380/data/pMHCI/features_out...</td>\n",
       "      <td>I</td>\n",
       "      <td>BA</td>\n",
       "      <td>residue</td>\n",
       "      <td>classif</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.764</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_100k_final_nostd_seed33_rmpssm_0</th>\n",
       "      <td>exp_100k_final_nostd_seed33_rmpssm_0_230529</td>\n",
       "      <td>./experiments/exp_100k_final_nostd_seed33_rmps...</td>\n",
       "      <td>29/May/2023_22:49:09</td>\n",
       "      <td>30/May/2023_03:24:54</td>\n",
       "      <td>['/projects/0/einf2380/data/pMHCI/features_out...</td>\n",
       "      <td>I</td>\n",
       "      <td>BA</td>\n",
       "      <td>residue</td>\n",
       "      <td>classif</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.715</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_100k_final_nostd_seed11_rmpssm_0</th>\n",
       "      <td>exp_100k_final_nostd_seed11_rmpssm_0_230529</td>\n",
       "      <td>./experiments/exp_100k_final_nostd_seed11_rmps...</td>\n",
       "      <td>29/May/2023_22:48:45</td>\n",
       "      <td>30/May/2023_02:38:32</td>\n",
       "      <td>['/projects/0/einf2380/data/pMHCI/features_out...</td>\n",
       "      <td>I</td>\n",
       "      <td>BA</td>\n",
       "      <td>residue</td>\n",
       "      <td>classif</td>\n",
       "      <td>all</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.749</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               exp_fullname  \\\n",
       "exp_id                                                                                        \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0  exp_100k_final_feat_trans_seed11_rmpssm_0_230530   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0            exp_100k_final_nostd_seed44_rmpssm_0_230529   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0            exp_100k_final_nostd_seed55_rmpssm_0_230529   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0            exp_100k_final_nostd_seed33_rmpssm_0_230529   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0            exp_100k_final_nostd_seed11_rmpssm_0_230529   \n",
       "\n",
       "                                                                                    exp_path  \\\n",
       "exp_id                                                                                         \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0  ./experiments/exp_100k_final_feat_trans_seed11...   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0       ./experiments/exp_100k_final_nostd_seed44_rmps...   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0       ./experiments/exp_100k_final_nostd_seed55_rmps...   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0       ./experiments/exp_100k_final_nostd_seed33_rmps...   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0       ./experiments/exp_100k_final_nostd_seed11_rmps...   \n",
       "\n",
       "                                                     start_time  \\\n",
       "exp_id                                                            \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0  30/May/2023_02:50:52   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0       29/May/2023_22:49:24   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0       29/May/2023_22:49:43   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0       29/May/2023_22:49:09   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0       29/May/2023_22:48:45   \n",
       "\n",
       "                                                       end_time  \\\n",
       "exp_id                                                            \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0  30/May/2023_05:29:15   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0       30/May/2023_03:26:25   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0       30/May/2023_03:26:09   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0       30/May/2023_03:24:54   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0       30/May/2023_02:38:32   \n",
       "\n",
       "                                                                             input_data_path  \\\n",
       "exp_id                                                                                         \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0  ['/projects/0/einf2380/data/pMHCI/features_out...   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0       ['/projects/0/einf2380/data/pMHCI/features_out...   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0       ['/projects/0/einf2380/data/pMHCI/features_out...   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0       ['/projects/0/einf2380/data/pMHCI/features_out...   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0       ['/projects/0/einf2380/data/pMHCI/features_out...   \n",
       "\n",
       "                                          protein_class target_data  \\\n",
       "exp_id                                                                \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0             I          BA   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0                  I          BA   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0                  I          BA   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0                  I          BA   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0                  I          BA   \n",
       "\n",
       "                                          resolution     task node_features  \\\n",
       "exp_id                                                                        \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0    residue  classif           all   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0         residue  classif           all   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0         residue  classif           all   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0         residue  classif           all   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0         residue  classif           all   \n",
       "\n",
       "                                           ... training_accuracy  \\\n",
       "exp_id                                     ...                     \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0  ...             0.792   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0       ...             0.764   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0       ...             0.758   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0       ...             0.753   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0       ...             0.766   \n",
       "\n",
       "                                          validation_accuracy  \\\n",
       "exp_id                                                          \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0               0.773   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0                    0.754   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0                    0.758   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0                    0.755   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0                    0.761   \n",
       "\n",
       "                                          testing_accuracy  \\\n",
       "exp_id                                                       \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0            0.777   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0                 0.747   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0                 0.753   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0                 0.760   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0                 0.752   \n",
       "\n",
       "                                           training_precision  \\\n",
       "exp_id                                                          \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0               0.734   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0                    0.715   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0                    0.726   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0                    0.772   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0                    0.746   \n",
       "\n",
       "                                           validation_precision  \\\n",
       "exp_id                                                            \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0                 0.711   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0                      0.690   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0                      0.727   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0                      0.777   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0                      0.744   \n",
       "\n",
       "                                           testing_precision  training_recall  \\\n",
       "exp_id                                                                          \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0              0.720            0.829   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0                   0.702            0.770   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0                   0.702            0.724   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0                   0.733            0.624   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0                   0.706            0.710   \n",
       "\n",
       "                                          validation_recall  testing_recall  \\\n",
       "exp_id                                                                        \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0             0.815           0.806   \n",
       "exp_100k_final_nostd_seed44_rmpssm_0                  0.798           0.739   \n",
       "exp_100k_final_nostd_seed55_rmpssm_0                  0.720           0.764   \n",
       "exp_100k_final_nostd_seed33_rmpssm_0                  0.622           0.715   \n",
       "exp_100k_final_nostd_seed11_rmpssm_0                  0.697           0.749   \n",
       "\n",
       "                                           test_clusters  \n",
       "exp_id                                                    \n",
       "exp_100k_final_feat_trans_seed11_rmpssm_0            NaN  \n",
       "exp_100k_final_nostd_seed44_rmpssm_0                 NaN  \n",
       "exp_100k_final_nostd_seed55_rmpssm_0                 NaN  \n",
       "exp_100k_final_nostd_seed33_rmpssm_0                 NaN  \n",
       "exp_100k_final_nostd_seed11_rmpssm_0                 NaN  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## Modify here\n",
    "exp_path = './experiments/'\n",
    "exp_ids = [\n",
    "    'exp_100k_final_bs64_seed11_rmpssm0',\n",
    "    'exp_100k_final_bs64_seed22_rmpssm0',\n",
    "    'exp_100k_final_bs64_seed33_rmpssm0',\n",
    "    'exp_100k_final_bs64_seed44_rmpssm0',\n",
    "    'exp_100k_final_bs64_seed55_rmpssm0',\n",
    "    'exp_100k_final_increase1_seed11_rmpssm_0',\n",
    "    'exp_100k_final_increase1_seed22_rmpssm_0',\n",
    "    'exp_100k_final_increase1_seed33_rmpssm_0',\n",
    "    'exp_100k_final_increase1_seed44_rmpssm_0',\n",
    "    'exp_100k_final_increase1_seed55_rmpssm_0',\n",
    "    'exp_100k_final_increase2_seed11_rmpssm_0',\n",
    "    'exp_100k_final_increase2_seed22_rmpssm_0',\n",
    "    'exp_100k_final_increase2_seed33_rmpssm_0',\n",
    "    'exp_100k_final_increase2_seed44_rmpssm_0',\n",
    "    'exp_100k_final_increase2_seed55_rmpssm_0',\n",
    "    ]\n",
    "exp_show_name=[\n",
    "               'One Convolutional Layer',\n",
    "               'One Convolutional Layer',\n",
    "               'One Convolutional Layer',\n",
    "               'One Convolutional Layer',\n",
    "               'One Convolutional Layer',\n",
    "               'Two Convolutional Layer',\n",
    "               'Two Convolutional Layer',\n",
    "               'Two Convolutional Layer',\n",
    "               'Two Convolutional Layer',\n",
    "               'Two Convolutional Layer',\n",
    "               'Three Convolutional Layer',\n",
    "               'Three Convolutional Layer',\n",
    "               'Three Convolutional Layer',\n",
    "               'Three Convolutional Layer',\n",
    "               'Three Convolutional Layer',\n",
    "               ]\n",
    "comparison_id = 'expandnn_experiment'\n",
    "exp_type = 'shuffle'\n",
    "exp_log = pd.read_excel(exp_path + '_experiments_log.xlsx', index_col='exp_id')\n",
    "exp_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder comparisons/standardize_experiment/ already exists!           \n",
      "Change comparison_id if you want to save plots for a different comparison.\n"
     ]
    }
   ],
   "source": [
    "######## Definitions used in the plotting\n",
    "comparisons_path = os.path.join(exp_path, 'comparisons')\n",
    "comparison_path = os.path.join(comparisons_path, comparison_id)\n",
    "\n",
    "if not os.path.exists(comparisons_path):\n",
    "    os.makedirs(comparisons_path)\n",
    "\n",
    "if not os.path.exists(comparison_path):\n",
    "    os.makedirs(comparison_path)\n",
    "else:\n",
    "    print(f'Folder comparisons/{comparison_id}/ already exists! \\\n",
    "          \\nChange comparison_id if you want to save plots for a different comparison.')\n",
    "\n",
    "def get_single_exp_df(exp_id, exp_log, exp_path):\n",
    "    exp_fullname = exp_log.loc[exp_id].exp_fullname\n",
    "    exp_path = os.path.join(exp_path, exp_fullname)\n",
    "    output_path = os.path.join(exp_path, 'output')\n",
    "    output_train = pd.read_hdf(os.path.join(output_path, 'output_exporter.hdf5'), key='training')\n",
    "    output_test = pd.read_hdf(os.path.join(output_path, 'output_exporter.hdf5'), key='testing')\n",
    "    df = pd.concat([output_train, output_test])\n",
    "    df.sort_values(by=['epoch'], inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC score bar comparison(testing set)\n",
    "\n",
    "palette = cycle(px.colors.qualitative.Plotly)\n",
    "\n",
    "auc_scores = []\n",
    "auc_scores_nn1 = []\n",
    "auc_scores_nn2 = []\n",
    "auc_scores_nn3 = []\n",
    "random_split=['Random_split1','Random_split2','Random_split3','Random_split4','Random_split5']\n",
    "\n",
    "\n",
    "avg_nn1=sum(auc_scores_nn1)/len(auc_scores_nn1)\n",
    "gap_avg_nn1=max(auc_scores_nn1)-avg_nn1\n",
    "name_nn1=f'Without Expansion (One Convolutional Layer): AUC={avg_nn1:.4f}Â±{gap_avg_nn1:.4f}'\n",
    "\n",
    "avg_nn2=sum(auc_scores_nn2)/len(auc_scores_nn2)\n",
    "gap_avg_nn2=max(auc_scores_nn2)-avg_nn2\n",
    "name_nn2=f'Expand to Two Convolutional Layers: AUC={avg_nn2:.4f}Â±{gap_avg_nn2:.4f}'\n",
    "\n",
    "avg_nn3=sum(auc_scores_nn3)/len(auc_scores_nn3)\n",
    "gap_avg_nn3=max(auc_scores_nn3)-avg_nn3\n",
    "name_nn3=f'Expand to Three Convolutional Layers: AUC={avg_nn3:.4f}Â±{gap_avg_nn3:.4f}'\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name= name_nn1, x=random_split, y = auc_scores_nn1),\n",
    "    go.Bar(name= name_nn2, x=random_split, y = auc_scores_nn2),\n",
    "    go.Bar(name= name_nn3, x=random_split, y = auc_scores_nn3)\n",
    "])\n",
    "\n",
    "fig.update_yaxes(title_text=\"AUC Score(Testing Set)\")\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    title=f'AUC Scores for Expand Neural Network Experiment(Testing Set)', #modify\n",
    "    title_x=0.5,\n",
    "    width=700, height=600,\n",
    "    yaxis_range=[0.80,0.89])\n",
    "fig.write_html(os.path.join(comparison_path, 'nn_auc_bars_testingset.html'))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC score bar comparison(validation set)\n",
    "\n",
    "\n",
    "palette = cycle(px.colors.qualitative.Plotly)\n",
    "\n",
    "auc_scores = []\n",
    "auc_scores_nn1 = []\n",
    "auc_scores_nn2 = []\n",
    "auc_scores_nn3 = []\n",
    "random_split=['Random_split1','Random_split2','Random_split3','Random_split4','Random_split5']\n",
    "\n",
    "\n",
    "avg_nn1=sum(auc_scores_nn1)/len(auc_scores_nn1)\n",
    "gap_avg_nn1=max(auc_scores_nn1)-avg_nn1\n",
    "name_nn1=f'Without Expansion (One Convolutional Layer): AUC={avg_nn1:.4f}Â±{gap_avg_nn1:.4f}'\n",
    "\n",
    "avg_nn2=sum(auc_scores_nn2)/len(auc_scores_nn2)\n",
    "gap_avg_nn2=max(auc_scores_nn2)-avg_nn2\n",
    "name_nn2=f'Expand to Two Convolutional Layers: AUC={avg_nn2:.4f}Â±{gap_avg_nn2:.4f}'\n",
    "\n",
    "avg_nn3=sum(auc_scores_nn3)/len(auc_scores_nn3)\n",
    "gap_avg_nn3=max(auc_scores_nn3)-avg_nn3\n",
    "name_nn3=f'Expand to Three Convolutional Layers: AUC={avg_nn3:.4f}Â±{gap_avg_nn3:.4f}'\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name= name_nn1, x=random_split, y = auc_scores_nn1),\n",
    "    go.Bar(name= name_nn2, x=random_split, y = auc_scores_nn2),\n",
    "    go.Bar(name= name_nn3, x=random_split, y = auc_scores_nn3)\n",
    "])\n",
    "\n",
    "fig.update_yaxes(title_text=\"AUC Score(Validation Set)\")\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    title=f'AUC Scores for Expand Neural Network Experiment(Validation Set)', #modify\n",
    "    title_x=0.5,\n",
    "    width=700, height=600,\n",
    "    yaxis_range=[0.80,0.89])\n",
    "fig.write_html(os.path.join(comparison_path, 'nn_auc_bars_validationset.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC score bar comparison(training set)\n",
    "\n",
    "\n",
    "palette = cycle(px.colors.qualitative.Plotly)\n",
    "\n",
    "auc_scores = []\n",
    "auc_scores_nn1 = []\n",
    "auc_scores_nn2 = []\n",
    "auc_scores_nn3 = []\n",
    "random_split=['Random_split1','Random_split2','Random_split3','Random_split4','Random_split5']\n",
    "\n",
    "\n",
    "avg_nn1=sum(auc_scores_nn1)/len(auc_scores_nn1)\n",
    "gap_avg_nn1=max(auc_scores_nn1)-avg_nn1\n",
    "name_nn1=f'Without Expansion (One Convolutional Layer): AUC={avg_nn1:.4f}Â±{gap_avg_nn1:.4f}'\n",
    "\n",
    "avg_nn2=sum(auc_scores_nn2)/len(auc_scores_nn2)\n",
    "gap_avg_nn2=max(auc_scores_nn2)-avg_nn2\n",
    "name_nn2=f'Expand to Two Convolutional Layers: AUC={avg_nn2:.4f}Â±{gap_avg_nn2:.4f}'\n",
    "\n",
    "avg_nn3=sum(auc_scores_nn3)/len(auc_scores_nn3)\n",
    "gap_avg_nn3=max(auc_scores_nn3)-avg_nn3\n",
    "name_nn3=f'Expand to Three Convolutional Layers: AUC={avg_nn3:.4f}Â±{gap_avg_nn3:.4f}'\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name= name_nn1, x=random_split, y = auc_scores_nn1),\n",
    "    go.Bar(name= name_nn2, x=random_split, y = auc_scores_nn2),\n",
    "    go.Bar(name= name_nn3, x=random_split, y = auc_scores_nn3)\n",
    "])\n",
    "\n",
    "fig.update_yaxes(title_text=\"AUC Score(Training Set)\")\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    title=f'AUC Scores for Expand Neural Network Experiment(Training Set)', #modify\n",
    "    title_x=0.5,\n",
    "    width=700, height=600,\n",
    "    yaxis_range=[0.80,0.89])\n",
    "fig.write_html(os.path.join(comparison_path, 'nn_auc_bars_trainingset.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## MCC bar plots(training set)\n",
    "palette = cycle(px.colors.qualitative.Plotly)\n",
    "\n",
    "mcc_nn1=[]\n",
    "mcc_nn2=[]\n",
    "mcc_nn3=[]\n",
    "\n",
    "thr = [\n",
    "       ] #modify, max mcc threshold\n",
    "\n",
    "avg_nn1=sum(mcc_nn1)/len(mcc_nn1)\n",
    "gap_avg_nn1=max(mcc_nn1)-avg_nn1\n",
    "name_nn1=f'Without Expansion (One Convolutional Layer): MCC={avg_nn1:.4f}Â±{gap_avg_nn1:.4f}'\n",
    "\n",
    "avg_nn2=sum(mcc_nn2)/len(mcc_nn2)\n",
    "gap_avg_nn2=max(mcc_nn2)-avg_nn2\n",
    "name_nn2=f'Expand to Two Convolutional Layers: MCC={avg_nn2:.4f}Â±{gap_avg_nn2:.4f}'\n",
    "\n",
    "avg_nn3=sum(mcc_nn3)/len(mcc_nn3)\n",
    "gap_avg_nn3=max(mcc_nn3)-avg_nn3\n",
    "name_nn3=f'Expand to Three Convolutional Layers: MCC={avg_nn3:.4f}Â±{gap_avg_nn3:.4f}'\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name= name_nn1, x=random_split, y = mcc_nn1),\n",
    "    go.Bar(name= name_nn2, x=random_split, y = mcc_nn2),\n",
    "    go.Bar(name= name_nn3, x=random_split, y = mcc_nn3),\n",
    "])\n",
    "\n",
    "fig.update_yaxes(title_text=\"MCC Score(Training Set)\")\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    title='MCC Scores for Expand Neural Network Experiment(Training Set)', #Modify\n",
    "    title_x=0.5,\n",
    "    width=800, height=500,\n",
    "    yaxis_range=[0.49,0.6])\n",
    "fig.write_html(os.path.join(comparison_path, 'nn_mcc_thr_trainingset.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## MCC bar plots(validation set)\n",
    "palette = cycle(px.colors.qualitative.Plotly)\n",
    "\n",
    "mcc_nn1=[]\n",
    "mcc_nn2=[]\n",
    "mcc_nn3=[]\n",
    "\n",
    "thr = [\n",
    "       ] #modify, max mcc threshold\n",
    "\n",
    "avg_nn1=sum(mcc_nn1)/len(mcc_nn1)\n",
    "gap_avg_nn1=max(mcc_nn1)-avg_nn1\n",
    "name_nn1=f'Without Expansion (One Convolutional Layer): MCC={avg_nn1:.4f}Â±{gap_avg_nn1:.4f}'\n",
    "\n",
    "avg_nn2=sum(mcc_nn2)/len(mcc_nn2)\n",
    "gap_avg_nn2=max(mcc_nn2)-avg_nn2\n",
    "name_nn2=f'Expand to Two Convolutional Layers: MCC={avg_nn2:.4f}Â±{gap_avg_nn2:.4f}'\n",
    "\n",
    "avg_nn3=sum(mcc_nn3)/len(mcc_nn3)\n",
    "gap_avg_nn3=max(mcc_nn3)-avg_nn3\n",
    "name_nn3=f'Expand to Three Convolutional Layers: MCC={avg_nn3:.4f}Â±{gap_avg_nn3:.4f}'\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name= name_nn1, x=random_split, y = mcc_nn1),\n",
    "    go.Bar(name= name_nn2, x=random_split, y = mcc_nn2),\n",
    "    go.Bar(name= name_nn3, x=random_split, y = mcc_nn3),\n",
    "])\n",
    "\n",
    "fig.update_yaxes(title_text=\"MCC Score(Validation Set)\")\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    title='MCC Scores for Expand Neural Network Experiment(Validation Set)', #Modify\n",
    "    title_x=0.5,\n",
    "    width=800, height=500,\n",
    "    yaxis_range=[0.49,0.6])\n",
    "fig.write_html(os.path.join(comparison_path, 'nn_mcc_thr_validationset.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## MCC bar plots(testing set)\n",
    "palette = cycle(px.colors.qualitative.Plotly)\n",
    "\n",
    "mcc_nn1=[]\n",
    "mcc_nn2=[]\n",
    "mcc_nn3=[]\n",
    "\n",
    "thr = [\n",
    "       ] #modify, max mcc threshold\n",
    "\n",
    "avg_nn1=sum(mcc_nn1)/len(mcc_nn1)\n",
    "gap_avg_nn1=max(mcc_nn1)-avg_nn1\n",
    "name_nn1=f'Without Expansion (One Convolutional Layer): MCC={avg_nn1:.4f}Â±{gap_avg_nn1:.4f}'\n",
    "\n",
    "avg_nn2=sum(mcc_nn2)/len(mcc_nn2)\n",
    "gap_avg_nn2=max(mcc_nn2)-avg_nn2\n",
    "name_nn2=f'Expand to Two Convolutional Layers: MCC={avg_nn2:.4f}Â±{gap_avg_nn2:.4f}'\n",
    "\n",
    "avg_nn3=sum(mcc_nn3)/len(mcc_nn3)\n",
    "gap_avg_nn3=max(mcc_nn3)-avg_nn3\n",
    "name_nn3=f'Expand to Three Convolutional Layers: MCC={avg_nn3:.4f}Â±{gap_avg_nn3:.4f}'\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name= name_nn1, x=random_split, y = mcc_nn1),\n",
    "    go.Bar(name= name_nn2, x=random_split, y = mcc_nn2),\n",
    "    go.Bar(name= name_nn3, x=random_split, y = mcc_nn3),\n",
    "])\n",
    "\n",
    "fig.update_yaxes(title_text=\"MCC Score(Testing Set)\")\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    title='MCC Scores for Expand Neural Network Experiment(Testing Set)', #Modify\n",
    "    title_x=0.5,\n",
    "    width=800, height=500,\n",
    "    yaxis_range=[0.49,0.6])\n",
    "fig.write_html(os.path.join(comparison_path, 'nn_mcc_thr_testingset.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Timings\n",
    "# times_bs16=[]\n",
    "# times_bs64=[]\n",
    "# times_bs128=[]\n",
    "# times_bs256=[]\n",
    "# times_bs512=[]\n",
    "# random_split=['Random_split1']\n",
    "# for exp_id in exp_ids:\n",
    "#     start = exp_log.loc[exp_id].start_time\n",
    "#     end = exp_log.loc[exp_id].end_time\n",
    "#     start_dt = datetime.strptime(start, '%d/%b/%Y_%H:%M:%S')\n",
    "#     end_dt = datetime.strptime(end, '%d/%b/%Y_%H:%M:%S')\n",
    "#     time = end_dt - start_dt\n",
    "\n",
    "    \n",
    "#     if \"16\" in exp_id:\n",
    "#         times_bs16.append(int(time.seconds/60))\n",
    "#     elif \"64\" in exp_id:\n",
    "#         times_bs64.append(int(time.seconds/60))\n",
    "#     elif \"128\" in exp_id:\n",
    "#         times_bs128.append(int(time.seconds/60))\n",
    "#     elif \"256\" in exp_id:\n",
    "#         times_bs256.append(int(time.seconds/60))\n",
    "#     elif \"512\" in exp_id:\n",
    "#         times_bs512.append(int(time.seconds/60))\n",
    "    \n",
    "\n",
    "# avg_bs16=sum(times_bs16)/len(times_bs16)\n",
    "# gap_avg_bs16=max(times_bs16)-avg_bs16\n",
    "# name_bs16=f'Batch Size 16: Min={times_bs16[0]:.0f}'\n",
    "\n",
    "# avg_bs64=sum(times_bs64)/len(times_bs64)\n",
    "# gap_avg_bs64=max(times_bs64)-avg_bs64\n",
    "# name_bs64=f'Batch Size 64: Min={times_bs64[0]:.0f}'\n",
    "\n",
    "# avg_bs128=sum(times_bs128)/len(times_bs128)\n",
    "# gap_avg_bs128=max(times_bs128)-avg_bs128\n",
    "# name_bs128=f'Batch Size 128: Min={times_bs128[0]:.0f}'\n",
    "\n",
    "# avg_bs256=sum(times_bs256)/len(times_bs256)\n",
    "# gap_avg_bs256=max(times_bs256)-avg_bs256\n",
    "# name_bs256=f'Batch Size 256: Min={times_bs256[0]:.0f}'\n",
    "\n",
    "# avg_bs512=sum(times_bs512)/len(times_bs512)\n",
    "# gap_avg_bs512=max(times_bs512)-avg_bs512\n",
    "# name_bs512=f'Batch Size 512: Min={times_bs512[0]:.0f}'\n",
    "\n",
    "# fig = go.Figure(data=[\n",
    "#     go.Bar(name= name_bs16, x=random_split, y = times_bs16),\n",
    "#     go.Bar(name= name_bs64, x=random_split, y = times_bs64),\n",
    "#     go.Bar(name= name_bs128, x=random_split, y = times_bs128),\n",
    "#     go.Bar(name= name_bs256, x=random_split, y = times_bs256),\n",
    "#     go.Bar(name= name_bs512, x=random_split, y = times_bs512)\n",
    "# ])\n",
    "\n",
    "# fig.update_yaxes(title_text=\"Minutes\")\n",
    "# fig.update_layout(\n",
    "#     barmode='group',\n",
    "#     title='Total timings for the experiments',\n",
    "#     title_x=0.5,\n",
    "#     width=600, height=500)\n",
    "# fig.write_html(os.path.join(comparison_path, 'timings.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final comparison with best batch size & original batch size (AUC) ###\n",
    "# x_group=['Training Set','Validation Set','Testing Set']\n",
    "# auc_nostd=[0.8408,0.8351,0.8285]\n",
    "# auc_std=[0.8787,0.8585,0.8523]\n",
    "# name_nostd=\"Without Standardization (Original)\"\n",
    "# name_std=\"With Standardization (Adopted)\"\n",
    "# fig = go.Figure(data=[\n",
    "#     go.Bar(name= name_nostd, x=x_group, y = auc_nostd, text = auc_nostd),\n",
    "#     go.Bar(name= name_std, x=x_group, y = auc_std, text = auc_std)\n",
    "# ])\n",
    "\n",
    "# fig.update_yaxes(title_text=\"AUC Score\")\n",
    "# fig.update_layout(\n",
    "#     barmode='group',\n",
    "#     title='Improvement of AUC Score for Expand Neural Network Experiment',\n",
    "#     title_x=0.5,\n",
    "#     width=800, height=600,\n",
    "#     yaxis_range=[0.80,0.89])\n",
    "# fig.write_html(os.path.join(comparison_path, 'final_nn_auc.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final comparison with best batch size & original batch size (MCC) ###\n",
    "# x_group=['Training Set','Validation Set','Testing Set']\n",
    "# mcc_nostd=[0.5219,0.5134,0.5032]\n",
    "# mcc_std=[0.5972,0.5571,0.5442]\n",
    "# name_nostd=\"Without Standardization (Original)\"\n",
    "# name_std=\"With Standardization (Adopted)\"\n",
    "# fig = go.Figure(data=[\n",
    "#     go.Bar(name= name_nostd, x=x_group, y = mcc_nostd, text = mcc_nostd),\n",
    "#     go.Bar(name= name_std, x=x_group, y = mcc_std, text = mcc_std)\n",
    "# ])\n",
    "\n",
    "# fig.update_yaxes(title_text=\"MCC Score\")\n",
    "# fig.update_layout(\n",
    "#     barmode='group',\n",
    "#     title='Improvement of MCC Score for Expand Neural Network Experiment',\n",
    "#     title_x=0.5,\n",
    "#     width=800, height=500,\n",
    "#     yaxis_range=[0.49,0.60])\n",
    "# fig.write_html(os.path.join(comparison_path, 'final_nn_mcc.html'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprank_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
