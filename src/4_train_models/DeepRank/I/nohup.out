Traceback (most recent call last):
  File "cnn_performances.py", line 9, in <module>
    from CNN.NeuralNet import NeuralNet
  File "/gpfs/home6/dmarz/3D-Vac/src/4_train_models/CNN/NeuralNet.py", line 8, in <module>
    import matplotlib
  File "/home/dmarz/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py", line 174, in <module>
    _check_versions()
  File "/home/dmarz/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py", line 168, in _check_versions
    module = importlib.import_module(modname)
  File "/home/dmarz/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/dmarz/anaconda3/lib/python3.7/site-packages/kiwisolver/__init__.py", line 8, in <module>
    from ._cext import (
ImportError: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.29' not found (required by /home/dmarz/anaconda3/lib/python3.7/site-packages/kiwisolver/_cext.cpython-37m-x86_64-linux-gnu.so)


========================================
=	 DeepRank Data Set
=
=	 Training data
=	 -> /projects/0/einf2380/data/pMHCI/features_output_folder/CNN/splits_HLA_quant_allele_clusters/clustered/0/test.hdf5
=
=
=
========================================

   Checking dataset Integrity


   Processing data set:
   Train dataset


   Data Set Info:
   Augmentation       : 0 rotations
   Training set       : 10399 conformations
   Validation set     : 0 conformations
   Test set           : 0 conformations
   Number of channels : 24
   Grid Size          : 35, 30, 30
/home/dmarz/anaconda3/envs/3dvac_test/lib/python3.10/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
       BatchNorm3d-1       [-1, 24, 35, 30, 30]              48
            Conv3d-2       [-1, 24, 35, 30, 30]             600
       BatchNorm3d-3       [-1, 24, 35, 30, 30]              48
              ReLU-4       [-1, 24, 35, 30, 30]               0
            Conv3d-5       [-1, 24, 33, 28, 28]             672
       BatchNorm3d-6       [-1, 24, 33, 28, 28]              48
              ReLU-7       [-1, 24, 33, 28, 28]               0
            Conv3d-8       [-1, 24, 31, 26, 26]           1,320
       BatchNorm3d-9       [-1, 24, 31, 26, 26]              48
        MaxPool3d-10       [-1, 24, 15, 13, 13]               0
             ReLU-11       [-1, 24, 15, 13, 13]               0
           Conv3d-12       [-1, 48, 13, 11, 11]          31,152
      BatchNorm3d-13       [-1, 48, 13, 11, 11]              96
        MaxPool3d-14          [-1, 48, 6, 5, 5]               0
             ReLU-15          [-1, 48, 6, 5, 5]               0
          Flatten-16                 [-1, 7200]               0
      BatchNorm1d-17                 [-1, 7200]          14,400
           Linear-18                  [-1, 128]         921,728
             ReLU-19                  [-1, 128]               0
          Dropout-20                  [-1, 128]               0
           Linear-21                  [-1, 128]          16,512
             ReLU-22                  [-1, 128]               0
          Dropout-23                  [-1, 128]               0
           Linear-24                    [-1, 2]             258
          Softmax-25                    [-1, 2]               0
================================================================
Total params: 986,930
Trainable params: 986,930
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 2.88
Forward/backward pass size (MB): 47.26
Params size (MB): 3.76
Estimated Total Size (MB): 53.91
----------------------------------------------------------------
Optimizer: sgd with learn rate: 0.001


========================================
=	 Convolution Neural Network
=	 model   : 3d
=	 CNN      : CnnClassGroupConv
=	 features : AtomicDensities_ind
=		     C_chain1
=		     C_chain2
=		     H_chain1
=		     H_chain2
=		     N_chain1
=		     N_chain2
=		     O_chain1
=		     O_chain2
=		     S_chain1
=		     S_chain2
=	 features : Feature_ind
=		     Edesolv_chain1
=		     Edesolv_chain2
=		     anch_chain1
=		     anch_chain2
=		     SkipGram_0_chain1
=		     SkipGram_0_chain2
=		     SkipGram_1_chain1
=		     SkipGram_1_chain2
=		     SkipGram_2_chain1
=		     SkipGram_2_chain2
=		     SkipGram_3_chain1
=		     SkipGram_3_chain2
=		     SkipGram_4_chain1
=		     SkipGram_4_chain2
=		     SkipGram_5_chain1
=		     SkipGram_5_chain2
=		     RCD_apolar-apolar_chain1
=		     RCD_apolar-apolar_chain2
=		     RCD_apolar-charged_chain1
=		     RCD_apolar-charged_chain2
=		     RCD_charged-charged_chain1
=		     RCD_charged-charged_chain2
=		     RCD_polar-apolar_chain1
=		     RCD_polar-apolar_chain2
=		     RCD_polar-charged_chain1
=		     RCD_polar-charged_chain2
=		     RCD_polar-polar_chain1
=		     RCD_polar-polar_chain2
=		     RCD_total_chain1
=		     RCD_total_chain2
=		     bsa_chain1
=		     bsa_chain2
=		     charge_chain1
=		     charge_chain2
=		     coulomb_chain1
=		     coulomb_chain2
=		     vdwaals_chain1
=		     vdwaals_chain2
=	 Pair     : add
=	 targets  : BIN_CLASS
=	 CUDA     : False
========================================

		-> mini-batch: 1 
		-> mini-batch: 2 
		-> mini-batch: 3 
		-> mini-batch: 4 
		-> mini-batch: 5 
		-> mini-batch: 6 
		-> mini-batch: 7 
		-> mini-batch: 8 
		-> mini-batch: 9 
		-> mini-batch: 10 
		-> mini-batch: 11 
		-> mini-batch: 12 
		-> mini-batch: 13 
		-> mini-batch: 14 
		-> mini-batch: 15 
		-> mini-batch: 16 
		-> mini-batch: 17 
		-> mini-batch: 18 
		-> mini-batch: 19 
		-> mini-batch: 20 
		-> mini-batch: 21 
		-> mini-batch: 22 
		-> mini-batch: 23 
		-> mini-batch: 24 
		-> mini-batch: 25 
		-> mini-batch: 26 
		-> mini-batch: 27 
		-> mini-batch: 28 
		-> mini-batch: 29 
		-> mini-batch: 30 
		-> mini-batch: 31 
		-> mini-batch: 32 
		-> mini-batch: 33 
		-> mini-batch: 34 
		-> mini-batch: 35 
		-> mini-batch: 36 
		-> mini-batch: 37 
		-> mini-batch: 38 
		-> mini-batch: 39 
		-> mini-batch: 40 
		-> mini-batch: 41 
		-> mini-batch: 42 
		-> mini-batch: 43 
		-> mini-batch: 44 
		-> mini-batch: 45 
		-> mini-batch: 46 
		-> mini-batch: 47 
		-> mini-batch: 48 
		-> mini-batch: 49 
		-> mini-batch: 50 
		-> mini-batch: 51 
		-> mini-batch: 52 
		-> mini-batch: 53 
		-> mini-batch: 54 
		-> mini-batch: 55 
		-> mini-batch: 56 
		-> mini-batch: 57 
		-> mini-batch: 58 
		-> mini-batch: 59 
		-> mini-batch: 60 
		-> mini-batch: 61 
		-> mini-batch: 62 
		-> mini-batch: 63 
		-> mini-batch: 64 
		-> mini-batch: 65 
		-> mini-batch: 66 
		-> mini-batch: 67 
		-> mini-batch: 68 
		-> mini-batch: 69 
		-> mini-batch: 70 
		-> mini-batch: 71 
		-> mini-batch: 72 
		-> mini-batch: 73 
		-> mini-batch: 74 
		-> mini-batch: 75 
		-> mini-batch: 76 
		-> mini-batch: 77 
		-> mini-batch: 78 
		-> mini-batch: 79 
		-> mini-batch: 80 
		-> mini-batch: 81 
		-> mini-batch: 82 
